# *created  "Mon Jan  8 12:42:30 2001" *by "Paul E. Black"
# *modified "Tue Feb 12 09:41:03 2019" *by "Paul E. Black"

# $Log: histogramSort.trm,v $
# Tue Feb 12 09:41:07 2019  Paul E. Black
# update access to rbaeza handbook
# 
# Revision 1.6  2009/11/16 14:52:19  black
# Update domain name of Ricardo Baeza-Yates' Handbook of Algorithms and Data Structures
#
# Revision 1.5  2009/09/30 17:20:44  black
# Update domain name of Raul Baeza's Handbook of Algorithms and Data Structures
#
# Revision 1.4  2006/06/02 18:13:35  black
# Clarifying the difference between histogram and counting sort.
#
# Revision 1.3  2004/12/17 14:49:59  black
# NOTE the contrast between bucket, histogram, and counting sorts.
#
# Revision 1.2  2004/12/17 14:39:11  black
# Add AKA interpolation sort.  Move Single Buffered Count Sort IMPL to
# counting sort.  Move GBY IMPL here from interpolation sort.  Refine
# XREFS into IMA, etc.  Add RCS keywords.  Make more XHTML compliant.
#

# entry name
@NAME=histogram sort
# _A_lgorithm, algo _T_echnique, _D_efinition, _P_roblem, or data _S_tructure
@TYPE=A
# autom basic theory search sort tree graph combin numeric etc. see areas.data
@AREA=sort
# the definition
@DEFN=An efficient 3-pass refinement of a {bucket sort} algorithm.  
The first pass
counts the number of items for each bucket in an auxiliary {array},
and then makes a running total so each auxiliary entry is the number of
preceding items.  The second pass puts each item in its proper bucket
according to the auxiliary entry for the {key} of that item.  The last
pass sorts each bucket.
# formal definition or {cross reference} to an entry
@FORML=
# comma-sep list of pure names that this is Also Known As.
@AKA=interpolation sort
# other cross-listings solely for the web, such as name or spelling variants
@WEB=

#    These are all comma-separated lists of {cross references}
# Generalization: "I am a kind of ..."
@IMA={bucket sort}
# Specialization: "... is a kind of me."
@VARIANT={counting sort}
# Aggregate parent: "I am a part of or used in ..."
@IMIN=
# Aggregate child: "... is a part of or used in me."
@INME=
# Other cross references that don't fit the above.  printed as "See also ..."
@XREFS={American flag sort}

# any notes.  these are not printed in the final dictionary
@NOTES=A bucket sort uses fixed-size buckets.  A histogram sort
sets up buckets of exactly the right size in a first pass.  A
counting sort is a histogram sort with one bucket per possible key
value.
</p>

<p>
The following note is due to Richard Harter, cri@tiac.net,
http://www.tiac.net/users/cri/, 8 January 2001, and is used by
permission.
</p>

<p>
The run time is effectively {O(n log log n)#big-O notation}.
Let S be the data set to be sorted, where $n=|S|$.  R is an
approximate rank function to sort the data into n bins.  R has the
following properties.
<ul>
<li>R is an integer valued function into [0, n-1].
<li>$0 \leq R(x) \leq n-1$ for x in S.
<li>For some x,y in S, R(x)=0 and R(y)=n-1.
<li>x &lt; y implies $R(x) \leq R(y)$ for x,y in S.
</ul>
Each bin then has, on average, 1 entry.  Under some rather broad
assumptions the number of entries in a bin will be Poisson distributed
whence the observation that the sort is O(n log log n).
</p>

<p>
Let T be the final array for the sorted data.  Allocate an auxiliary
integer array H indexed $0 \ldots n-1$.  
We make one pass through the data to count the number of items in
each bin, recording the counts in H.  The array H is then
converted into a cumulative array so each entry in H specifies the
beginning bin position of the bin contents in T.  We then make a
second pass through the data.  We copy each item x in S from S to T at
H(R(x)), then increment H(R(x)) so the next item in the bin goes in
the next location in T.  (The bin number R(x) could be saved in still
another auxiliary array to trade off memory for computation.)
</p>

<p>
For numeric data, there is a simple R function that works very well:
Let min, max be the minimum and maximum of S.  Then R(x) = n*(x -
min)/(max-min).
</p>

<p>
This uses quite a bit of extra memory.  For large data sets, there
could be slow downs because of page faults.  For large n it is more
efficient to bound the number of bins.
# further explanation (pure HTML)
@LINKS=
# implementation(s) (pure HTML)
@IMPL=<a
href="https://users.dcc.uchile.cl/~rbaeza/handbook/algs/4/416.sort.c">(C
and Pascal)</a>.
# GBY91 pp 166-168

# author's initials (see authors.data)
@AUTHOR=PEB
# end $Source: /home/black/Workspace/dads/Terms/RCS/histogramSort.trm,v $
